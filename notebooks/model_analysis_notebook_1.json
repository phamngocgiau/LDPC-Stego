{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDPC Steganography - Neural Network Model Analysis\n",
    "\n",
    "This notebook provides detailed analysis of the neural network architectures used in the LDPC steganography system.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Model Architecture Overview](#architecture)\n",
    "2. [Encoder Network Analysis](#encoder)\n",
    "3. [Decoder Network Analysis](#decoder)\n",
    "4. [Attention Mechanisms](#attention)\n",
    "5. [Recovery CVAE Analysis](#recovery)\n",
    "6. [Performance Profiling](#profiling)\n",
    "7. [Gradient Flow Analysis](#gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchsummary import summary\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Import model components\n",
    "from configs.ldpc_config import LDPCConfig\n",
    "from core.adaptive_ldpc import create_ldpc_system\n",
    "from models.steganography_model import AdvancedSteganographyModelWithLDPC\n",
    "from models.encoders.ldpc_aware_encoder import LDPCAwareDualUNetEncoder\n",
    "from models.decoders.ldpc_aware_decoder import LDPCAwareDualUNetDecoder\n",
    "from models.recovery.recovery_cvae import RecoveryCVAE\n",
    "from models.attention.self_attention import SelfAttention\n",
    "from models.attention.cross_attention import CrossAttention\n",
    "from models.blocks.conv_block import ConvBlock\n",
    "from models.blocks.residual_block import ResidualBlock\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"üß† Neural Network Model Analysis Notebook\")\n",
    "print(\"üìö All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Architecture Overview {#architecture}\n",
    "\n",
    "Let's start by analyzing the overall architecture of our steganography system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the complete model for analysis\n",
    "print(\"üèóÔ∏è Building Complete Model Architecture\")\n",
    "\n",
    "config = LDPCConfig()\n",
    "config.device = 'cpu'\n",
    "config.image_size = 256\n",
    "config.channels = 3\n",
    "config.message_length = 1024\n",
    "config.batch_size = 4\n",
    "config.unet_base_channels = 64\n",
    "config.unet_depth = 5\n",
    "config.attention_layers = [5, 10, 15, 20]\n",
    "\n",
    "# Create LDPC system\n",
    "ldpc_system = create_ldpc_system(config)\n",
    "\n",
    "# Create complete model\n",
    "model = AdvancedSteganographyModelWithLDPC(config, ldpc_system)\n",
    "\n",
    "print(f\"‚úÖ Model created successfully!\")\n",
    "print(f\"  Image size: {config.image_size}x{config.image_size}\")\n",
    "print(f\"  Channels: {config.channels}\")\n",
    "print(f\"  Message length: {config.message_length}\")\n",
    "print(f\"  UNet depth: {config.unet_depth}\")\n",
    "print(f\"  Base channels: {config.unet_base_channels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model parameters\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count trainable parameters in model\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def analyze_model_components(model):\n",
    "    \"\"\"Analyze parameters in each component\"\"\"\n",
    "    components = {}\n",
    "    \n",
    "    if hasattr(model, 'encoder'):\n",
    "        components['Encoder'] = count_parameters(model.encoder)\n",
    "    \n",
    "    if hasattr(model, 'decoder'):\n",
    "        components['Decoder'] = count_parameters(model.decoder)\n",
    "    \n",
    "    if hasattr(model, 'recovery_cvae'):\n",
    "        components['Recovery CVAE'] = count_parameters(model.recovery_cvae)\n",
    "    \n",
    "    if hasattr(model, 'discriminator'):\n",
    "        components['Discriminator'] = count_parameters(model.discriminator)\n",
    "    \n",
    "    return components\n",
    "\n",
    "# Analyze the complete model\n",
    "total_params = count_parameters(model)\n",
    "components = analyze_model_components(model)\n",
    "\n",
    "print(f\"üìä Model Parameter Analysis:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Total size (MB): {total_params * 4 / 1024 / 1024:.2f}\")\n",
    "\n",
    "print(f\"\\nüîß Component breakdown:\")\n",
    "for component, params in components.items():\n",
    "    percentage = (params / total_params) * 100\n",
    "    print(f\"  {component}: {params:,} ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualize parameter distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Pie chart\n",
    "ax1.pie(components.values(), labels=components.keys(), autopct='%1.1f%%', startangle=90)\n",
    "ax1.set_title('Model Parameter Distribution', fontsize=14, weight='bold')\n",
    "\n",
    "# Bar chart\n",
    "bars = ax2.bar(range(len(components)), list(components.values()), \n",
    "               color=sns.color_palette(\"husl\", len(components)))\n",
    "ax2.set_xlabel('Model Components')\n",
    "ax2.set_ylabel('Number of Parameters')\n",
    "ax2.set_title('Parameter Count by Component', fontsize=14, weight='bold')\n",
    "ax2.set_xticks(range(len(components)))\n",
    "ax2.set_xticklabels(components.keys(), rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, value) in enumerate(zip(bars, components.values())):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(components.values())*0.01, \n",
    "            f'{value:,}', ha='center', va='bottom', fontsize=10, rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Encoder Network Analysis {#encoder}\n",
    "\n",
    "Deep dive into the LDPC-aware encoder architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze encoder architecture\n",
    "print(\"üîç Encoder Architecture Analysis\")\n",
    "\n",
    "encoder = model.encoder\n",
    "encoder_params = count_parameters(encoder)\n",
    "\n",
    "print(f\"Encoder parameters: {encoder_params:,}\")\n",
    "print(f\"Encoder size (MB): {encoder_params * 4 / 1024 / 1024:.2f}\")\n",
    "\n",
    "# Test encoder with sample inputs\n",
    "cover_images = torch.randn(2, config.channels, config.image_size, config.image_size)\n",
    "sample_message = torch.randint(0, 2, (2, config.message_length), dtype=torch.float32)\n",
    "\n",
    "# Encode message with LDPC first\n",
    "encoded_message = ldpc_system.encode(sample_message, attack_strength=0.3)\n",
    "\n",
    "print(f\"\\nüìè Input/Output